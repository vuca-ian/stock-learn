{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from torchsummary import summary\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleStockDataset(Dataset):\n",
    "    \"\"\"多模尺度数据集\"\"\"\n",
    "    def __init__(self, scale_factors, seq_length=24, pred_length=4, data_path='./'):\n",
    "        self.standardScaler = StandardScaler()\n",
    "        self.scale_factors = scale_factors\n",
    "        self.seq_length = seq_length\n",
    "        self.pred_length = pred_length\n",
    "        self.data_path = data_path\n",
    "        self.data = {\n",
    "            scale: self._generate_synthetic_data(scale) for scale in self.scale_factors\n",
    "        }\n",
    "        # 验证数据维度\n",
    "        for scale, data in self.data.items():\n",
    "            assert len(data) > seq_length + pred_length, \\\n",
    "                f\"{scale}数据长度不足，需要至少{seq_length + pred_length}个样本\"\n",
    "            assert data.shape[1] == 4, \\\n",
    "                f\"{scale}数据特征维度应为4，实际为{data.shape[1]}\"\n",
    "    \n",
    "    def _generate_synthetic_data(self, scale):\n",
    "        \"\"\"获取合成数据\"\"\"\n",
    "        data = pd.read_csv(self.data_path + f'train-{scale}.csv', \n",
    "                           usecols=['date','open', 'high', 'low', 'close'],\n",
    "                           parse_dates=['date'], index_col='date')\n",
    "        return self.standardScaler.fit_transform(data)\n",
    "    \n",
    "    def _align_scales(self, idx):\n",
    "        \"\"\"三线性插值对齐时间轴\"\"\"\n",
    "        aligned = {}\n",
    "        base_idx = idx // 8  # 对齐到日线级别\n",
    "        for scale in self.scale_factors:\n",
    "            ratio = {'30min':48, '1hour':24, '4hour':6, '1day':1}[scale]\n",
    "            # start = int(base_idx * ratio)\n",
    "            scale_idx = int(base_idx * ratio)\n",
    "            seq_items = int(self.seq_length * ratio)\n",
    "\n",
    "            aligned_seq = self.data[scale][scale_idx:scale_idx + seq_items]\n",
    "            # 添加空数据检查\n",
    "            if len(aligned_seq) == 0:\n",
    "                aligned_seq = np.zeros((self.seq_length, 4))  # 用零填充\n",
    "            # Linear interpolation if needed\n",
    "            if len(aligned_seq) < self.seq_length:\n",
    "                x_orig = np.arange(len(aligned_seq))\n",
    "                x_new = np.linspace(0, len(aligned_seq)-1, self.seq_length)\n",
    "                aligned_seq = np.array([np.interp(x_new, x_orig, col) \n",
    "                                    for col in aligned_seq.T]).T\n",
    "                \n",
    "            aligned[scale] = aligned_seq[:self.seq_length]\n",
    "        return aligned\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self._align_scales(idx)\n",
    "         # 确保填充后的维度一致性\n",
    "        for k,v in inputs.items():\n",
    "            assert v.shape[1] == 4, f\"特征维度错误: {k}的维度为{v.shape[1]}\"\n",
    "\n",
    "        # target = self.data['30min'][idx:idx+self.pred_length, 0]  # 预测未来价格\n",
    "         # 统一所有尺度特征维度为4\n",
    "        aligned = {k: np.pad(v, ((0,0),(0,1))) if v.shape[1]==3 else v \n",
    "              for k,v in inputs.items()}\n",
    "        target = self.data['30min'][idx+self.pred_length-1, 0]  # 从[4]变为标量\n",
    "        # 双重验证\n",
    "        assert isinstance(target, np.float64), \"目标值类型错误\"\n",
    "        target_tensor = torch.tensor(target, dtype=torch.float32)\n",
    "        return {k:torch.FloatTensor(v) for k,v in aligned.items()}, target_tensor\n",
    "    def __len__(self):\n",
    "        return len(self.data[self.scale_factors[0]]) - self.pred_length - self.seq_length\n",
    "\n",
    "class ScaleAwareExpert(nn.Module):\n",
    "    \"\"\"专家\"\"\"\n",
    "    def __init__(self, input_dim, scale_type):\n",
    "        super().__init__()\n",
    "        self.scale_type = scale_type\n",
    "\n",
    "        if '30min' in scale_type or '1h' in scale_type:\n",
    "            \"\"\"高频专家: CNN + BiLSTM \"\"\"\n",
    "            self.conv = nn.Conv1d(input_dim,\n",
    "                                  out_channels=16,\n",
    "                                  kernel_size=3, \n",
    "                                  padding='same', \n",
    "                                  )\n",
    "            self.lstm = nn.LSTM(16,32, num_layers=2, batch_first=True, bidirectional=True)\n",
    "            self.proj = nn.Linear(64,32)\n",
    "        else:\n",
    "            \"\"\"低频专家: LSTM \"\"\"\n",
    "            self.proj_in = nn.Linear(input_dim, 4)  # 3维→4维\n",
    "            self.encoder_layer = nn.TransformerEncoderLayer(d_model=4, nhead=2, dim_feedforward=64, batch_first=True)\n",
    "            self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
    "            self.proj = nn.Linear(4, 32)\n",
    "        self.predictor = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if '30min' in self.scale_type or '1h' in self.scale_type:\n",
    "            x = self.conv(x.permute(0,2,1)).permute(0,2,1)\n",
    "            x, _ = self.lstm(x)\n",
    "            x = x[:, -1, :]  # 取最后一个时间步 [batch, 4]\n",
    "            x = self.proj(x)\n",
    "        else:\n",
    "            x = self.proj_in(x)\n",
    "            x = self.transformer(x)\n",
    "            x = self.proj(x[:,-1,:]) # 只取最后一个时间步的输出\n",
    "        return self.predictor(x)\n",
    "class MoE(nn.Module):\n",
    "    \"\"\"混合专家网络\"\"\"\n",
    "    def __init__(self, input_dim=4, experts=['30min','1hour','4hour','1day'], hidden_dim=64, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleDict({\n",
    "            scale: ScaleAwareExpert(input_dim, scale) for scale in experts\n",
    "        })\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(input_dim * len(experts), hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, len(experts)),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        expert_outputs = {}\n",
    "        for scale, expert in self.experts.items():\n",
    "            # expert_outputs[scale] = expert(inputs[scale])\n",
    "            expert_outputs[scale] = expert(inputs[scale]).squeeze(-1)  # [32,1] -> [32]\n",
    "        # 动态门控\n",
    "        gate_input = torch.cat([v for v in inputs.values()], dim=-1)\n",
    "        weights = self.gate(gate_input.mean(dim=1))  # (batch, num_experts)\n",
    "        \n",
    "        # 加权融合\n",
    "        combined = sum(weights[:, i] * expert_outputs[scale] \n",
    "                      for i, scale in enumerate(self.experts.keys()))\n",
    "        return combined.unsqueeze(-1), expert_outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 评估指标 ==================== \n",
    "def sharpe_ratio(returns, risk_free=0.0):\n",
    "    excess_returns = returns - risk_free\n",
    "    return excess_returns.mean() / excess_returns.std()\n",
    "\n",
    "def max_drawdown(returns):\n",
    "    cumulative = returns.cumsum()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    drawdown = (peak - cumulative).max()\n",
    "    return drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 维度跟踪 ===\n",
      "卷积后维度: torch.Size([2, 24, 16])\n",
      "LSTM后维度: torch.Size([2, 24, 64])\n",
      "Proj后维度: torch.Size([2, 24, 32])\n",
      "最终输出维度: torch.Size([2, 1])\n",
      "测试通过，输出维度: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "def test_conv_layer():\n",
    "    # 模拟输入 (batch=2, seq=24, features=4)\n",
    "    test_input = torch.randn(2, 24, 4)\n",
    "    expert = ScaleAwareExpert(input_dim=4, scale_type='30min')\n",
    "    \n",
    "    # 添加维度跟踪\n",
    "    print(\"=== 维度跟踪 ===\")\n",
    "    x = expert.conv(test_input.permute(0,2,1)).permute(0,2,1)\n",
    "    print(f\"卷积后维度: {x.shape}\")  # 应显示[2,24,16]\n",
    "    \n",
    "    x, _ = expert.lstm(x)\n",
    "    print(f\"LSTM后维度: {x.shape}\")  # 应显示[2,24,64]\n",
    "    \n",
    "    x = expert.proj(x)\n",
    "    print(f\"Proj后维度: {x.shape}\")  # 应显示[2,24,32]\n",
    "    \n",
    "    output = expert(test_input)\n",
    "    print(f\"最终输出维度: {output.shape}\")  # 应显示[2,1]\n",
    "    # 前向传播检查\n",
    "    try:\n",
    "        output = expert(test_input)\n",
    "        print(f\"测试通过，输出维度: {output.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"测试失败: {str(e)}\")\n",
    "\n",
    "test_conv_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 低频专家维度跟踪 ===\n",
      "投影后维度: torch.Size([2, 24, 4])\n",
      "转置后维度: torch.Size([24, 2, 4])\n",
      "Transformer后维度: torch.Size([24, 2, 4])\n",
      "最终输出维度: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# 测试低频专家\n",
    "def test_low_freq_expert():\n",
    "    test_input = torch.randn(2, 24, 4)\n",
    "    expert = ScaleAwareExpert(input_dim=4, scale_type='4hour')\n",
    "    \n",
    "    print(\"=== 低频专家维度跟踪 ===\")\n",
    "    x = expert.proj_in(test_input)\n",
    "    print(f\"投影后维度: {x.shape}\")  # [2,24,4]\n",
    "    \n",
    "    x = x.permute(1,0,2)\n",
    "    print(f\"转置后维度: {x.shape}\")  # [24,2,4]\n",
    "    \n",
    "    x = expert.transformer(x)\n",
    "    print(f\"Transformer后维度: {x.shape}\")  # [24,2,4]\n",
    "    \n",
    "    output = expert(test_input)\n",
    "    print(f\"最终输出维度: {output.shape}\")  # [2,1]\n",
    "\n",
    "test_low_freq_expert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(loss_history, expert_weights, targets, predictions):\n",
    "    \"\"\"训练过程可视化分析\"\"\"\n",
    "    plt.figure(figsize=(15,5))\n",
    "    \n",
    "    # 损失曲线\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(loss_history, label='Training Loss')\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\"), plt.ylabel(\"Loss\")\n",
    "    \n",
    "    # 专家权重分布\n",
    "    plt.subplot(1,3,2)\n",
    "    sns.heatmap(np.array(expert_weights), cmap='viridis', \n",
    "                xticklabels=['30min','1h','4h','1d'])\n",
    "    plt.title(\"Expert Weights Distribution\")\n",
    "    plt.xlabel(\"Experts\"), plt.ylabel(\"Epoch\")\n",
    "    \n",
    "    # 预测结果示例\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.scatter(targets[:100], predictions[:100], alpha=0.5)\n",
    "    plt.plot([min(targets), max(targets)], [min(targets), max(targets)], 'r--')\n",
    "    plt.title(\"Predictions vs Ground Truth\")\n",
    "    plt.xlabel(\"True Values\"), plt.ylabel(\"Predictions\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 训练逻辑 ====================\n",
    "def hybrid_loss(pred, target, expert_outs, alpha=0.7):\n",
    "    pred = pred.squeeze(-1)  # (32,1) → (32)\n",
    "    target = target.squeeze()  # [32] remains\n",
    "    mse = nn.MSELoss()\n",
    "    main_loss = mse(pred, target)\n",
    "    \n",
    "    # 趋势一致性约束\n",
    "    expert_tensor = torch.stack(list(expert_outs.values()))  # [num_experts, batch]\n",
    "    # trends = torch.sign(expert_tensor.detach())  # [num_experts, batch]\n",
    "    trends = torch.stack([\n",
    "        torch.sign(expert_outs['30min'].detach()),\n",
    "        torch.sign(expert_outs['1hour'].detach()), \n",
    "        torch.sign(expert_outs['4hour'].detach()),\n",
    "        torch.sign(expert_outs['1day'].detach())\n",
    "    ])\n",
    "    # trends = torch.stack([torch.sign(out.detach()) for out in expert_outs.values()])\n",
    "    consistency = torch.mean(torch.prod(trends, dim=0))\n",
    "    \n",
    "    return alpha*main_loss + (1-alpha)*(1 - consistency)\n",
    "\n",
    "def print_model_summary(model, device):\n",
    "    \"\"\"兼容多输入结构的模型摘要\"\"\"\n",
    "    input_data = [\n",
    "        torch.randn(1, 24, 4).to(device),  # 30min\n",
    "        torch.randn(1, 24, 4).to(device),  # 1hour\n",
    "        torch.randn(1, 24, 4).to(device),  # 4hour\n",
    "        torch.randn(1, 24, 4).to(device),  # 1day\n",
    "    ]\n",
    "    \n",
    "    # 打印摘要\n",
    "    summary(model,\n",
    "            input_data=input_data,\n",
    "            device=device,\n",
    "            col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "            depth=3,\n",
    "            verbose=0\n",
    "           )\n",
    "    \n",
    "    # model.forward = original_forward\n",
    "    # # 调整模型forward方法临时适配\n",
    "    # original_forward = model.forward\n",
    "    # model.forward = lambda x1,x2,x3,x4: original_forward({\n",
    "    #     '30min': x1, \n",
    "    #     '1hour': x2,\n",
    "    #     '4hour': x3, \n",
    "    #     '1day': x4\n",
    "    # })[0]  # 只返回预测结果\n",
    "    \n",
    "    # summary(model, \n",
    "    #        input_size=[(24,4)]*4, \n",
    "    #        device=str(device),  # 关键修改点\n",
    "    #        batch_size=1\n",
    "    #        )\n",
    "    # model.forward = original_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据特征维度: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dataset = MultiScaleStockDataset(data_path='../data/', scale_factors=['30min', '1hour', '4hour', '1day'])\n",
    "    \n",
    "    print(f\"数据特征维度: {dataset.data['30min'].shape[1]}\")\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    model = MoE(input_dim=4).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "    # print_model_summary(model, device)\n",
    "    # 添加可视化数据收集\n",
    "    loss_history = []\n",
    "    expert_weights = []\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    for epoch in range(50):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for batch_idx, (inputs, target) in enumerate(loader):\n",
    "            inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "            target = target.to(device)\n",
    "            \n",
    "            pred, expert_outs = model(inputs)\n",
    "            loss = hybrid_loss(pred, target, expert_outs)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # 收集预测结果\n",
    "            with torch.no_grad():\n",
    "                preds = pred.squeeze().cpu().numpy()\n",
    "                predictions.extend(preds)\n",
    "                targets.extend(target.cpu().numpy())\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        # 记录专家权重\n",
    "        with torch.no_grad():\n",
    "            dummy_input = {k: torch.randn(1,24,4).to(device) for k in model.experts}\n",
    "            _, weights = model(dummy_input)\n",
    "            # expert_weights.append(weights.cpu().numpy()[0])\n",
    "            expert_weights.append([\n",
    "                list(model.experts['30min'].parameters())[0].detach().cpu().numpy().mean(),\n",
    "                list(model.experts['1hour'].parameters())[0].detach().cpu().numpy().mean(),\n",
    "                list(model.experts['4hour'].parameters())[0].detach().cpu().numpy().mean(),\n",
    "                list(model.experts['1day'].parameters())[0].detach().cpu().numpy().mean()\n",
    "            ])\n",
    "        \n",
    "        avg_loss = epoch_loss / len(loader)\n",
    "        loss_history.append(avg_loss)    \n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch} Loss: {loss.item():.4f}')\n",
    "    visualize_training(loss_history, expert_weights, targets=targets, predictions=predictions)\n",
    "    return model\n",
    "model = train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_experts(model, device, test_loader):\n",
    "    \"\"\"各专家输出分析\"\"\"\n",
    "    expert_outputs = {name: [] for name in model.experts}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "            _, outputs = model(inputs)\n",
    "            \n",
    "            for name, out in outputs.items():\n",
    "                expert_outputs[name].extend(out.squeeze().cpu().numpy())\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    for name, values in expert_outputs.items():\n",
    "        sns.kdeplot(values, label=name, alpha=0.6)\n",
    "    plt.title(\"Expert Output Distributions\")\n",
    "    plt.xlabel(\"Prediction Value\"), plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\\\n=== Expert Analysis ===\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_dataset = MultiScaleStockDataset(\n",
    "    data_path='../data/', \n",
    "    scale_factors=['30min', '1hour', '4hour', '1day']\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "analyze_experts(model,device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
