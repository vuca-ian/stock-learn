{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleStockDataset(Dataset):\n",
    "    \"\"\"多模尺度数据集\"\"\"\n",
    "    def __init__(self, scale_factors, seq_length=24, pred_length=4, data_path='./'):\n",
    "        self.standardScaler = StandardScaler()\n",
    "        self.scale_factors = scale_factors\n",
    "        self.seq_length = seq_length\n",
    "        self.pred_length = pred_length\n",
    "        self.data_path = data_path\n",
    "        self.data = {\n",
    "            scale: self._generate_synthetic_data(scale) for scale in self.scale_factors\n",
    "        }\n",
    "    \n",
    "    def _generate_synthetic_data(self, scale):\n",
    "        \"\"\"获取合成数据\"\"\"\n",
    "        data = pd.read_csv(self.data_path + f'train-{scale}.csv', \n",
    "                           usecols=['date','open', 'high', 'low', 'close'],\n",
    "                           parse_dates=['date'], index_col='date')\n",
    "        return self.standardScaler.fit_transform(data)\n",
    "    \n",
    "    def _align_scales(self, idx):\n",
    "        \"\"\"三线性插值对齐时间轴\"\"\"\n",
    "        aligned = {}\n",
    "        base_idx = idx // 8  # 对齐到日线级别\n",
    "        for scale in self.scale_factors:\n",
    "            ratio = {'30min':8, '1hour':4, '4hour':1, '1day':1/24}[scale]\n",
    "            start = int(base_idx * ratio)\n",
    "            aligned[scale] = self.data[scale][start:start+self.seq_length]\n",
    "        return aligned\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self._align_scales(idx)\n",
    "         # 确保填充后的维度一致性\n",
    "        for k,v in inputs.items():\n",
    "            assert v.shape[1] == 4, f\"特征维度错误: {k}的维度为{v.shape[1]}\"\n",
    "\n",
    "        # target = self.data['30min'][idx:idx+self.pred_length, 0]  # 预测未来价格\n",
    "         # 统一所有尺度特征维度为4\n",
    "        aligned = {k: np.pad(v, ((0,0),(0,1))) if v.shape[1]==3 else v \n",
    "              for k,v in inputs.items()}\n",
    "        target = self.data['30min'][idx+self.pred_length-1, 0]  # 从[4]变为标量\n",
    "        # 双重验证\n",
    "        assert isinstance(target, np.float64), \"目标值类型错误\"\n",
    "        target_tensor = torch.tensor(target, dtype=torch.float32)\n",
    "        return {k:torch.FloatTensor(v) for k,v in aligned.items()}, target_tensor\n",
    "    def __len__(self):\n",
    "        return len(self.data[self.scale_factors[0]]) - self.pred_length - self.seq_length\n",
    "\n",
    "class ScaleAwareExpert(nn.Module):\n",
    "    \"\"\"专家\"\"\"\n",
    "    def __init__(self, input_dim, scale_type):\n",
    "        super().__init__()\n",
    "        self.scale_type = scale_type\n",
    "\n",
    "        if '30min' in scale_type or '1h' in scale_type:\n",
    "            \"\"\"高频专家: CNN + BiLSTM \"\"\"\n",
    "            self.conv = nn.Conv1d(input_dim,\n",
    "                                  out_channels=16,\n",
    "                                  kernel_size=3, \n",
    "                                  padding='same', \n",
    "                                  )\n",
    "            self.lstm = nn.LSTM(16,32, num_layers=2, batch_first=True, bidirectional=True)\n",
    "            self.proj = nn.Linear(64,32)\n",
    "        else:\n",
    "            \"\"\"低频专家: LSTM \"\"\"\n",
    "            self.proj_in = nn.Linear(input_dim, 4)  # 3维→4维\n",
    "            self.encoder_layer = nn.TransformerEncoderLayer(d_model=4, nhead=2, dim_feedforward=64)\n",
    "            self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
    "            self.proj = nn.Linear(4, 32)\n",
    "        self.predictor = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"输入维度: {x.shape}\")  # 应显示(batch, seq_len, 4)\n",
    "        if '30min' in self.scale_type or '1h' in self.scale_type:\n",
    "            x = self.conv(x.permute(0,2,1)).permute(0,2,1)\n",
    "            x, _ = self.lstm(x)\n",
    "            x = x[:, -1, :]  # 取最后一个时间步 [batch, 4]\n",
    "            x = self.proj(x)\n",
    "        else:\n",
    "            x = self.proj_in(x)\n",
    "            x = self.transformer(x)\n",
    "            x = self.proj(x[:,-1,:]) # 只取最后一个时间步的输出\n",
    "        return self.predictor(x)\n",
    "class MoE(nn.Module):\n",
    "    \"\"\"混合专家网络\"\"\"\n",
    "    def __init__(self, input_dim=4, experts=['30min','1hour','4hour','1day'], hidden_dim=64, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleDict({\n",
    "            scale: ScaleAwareExpert(input_dim, scale) for scale in experts\n",
    "        })\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(input_dim * len(experts), hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, len(experts)),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        expert_outputs = {}\n",
    "        for scale, expert in self.experts.items():\n",
    "            expert_outputs[scale] = expert(inputs[scale])\n",
    "        # 动态门控\n",
    "        gate_input = torch.cat([v for v in inputs.values()], dim=-1)\n",
    "        weights = self.gate(gate_input.mean(dim=1))  # (batch, num_experts)\n",
    "        \n",
    "        # 加权融合\n",
    "        combined = sum(weights[:, i] * expert_outputs[scale] \n",
    "                      for i, scale in enumerate(self.experts.keys()))\n",
    "        return combined, expert_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 训练逻辑 ====================\n",
    "def hybrid_loss(pred, target, expert_outs, alpha=0.7):\n",
    "    pred = pred.squeeze(-1)  # (32,1) → (32)\n",
    "    mse = nn.MSELoss()\n",
    "    main_loss = mse(pred, target)\n",
    "    \n",
    "    # 趋势一致性约束\n",
    "    trends = torch.stack([torch.sign(out.detach()) for out in expert_outs.values()])\n",
    "    consistency = torch.mean(torch.prod(trends, dim=0))\n",
    "    \n",
    "    return alpha*main_loss + (1-alpha)*(1 - consistency)\n",
    "def train():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dataset = MultiScaleStockDataset(data_path='../data/', scale_factors=['30min', '1hour', '4hour', '1day'])\n",
    "    \n",
    "    print(f\"数据特征维度: {dataset.data['30min'].shape[1]}\")\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    model = MoE(input_dim=4).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        for batch_idx, (inputs, target) in enumerate(loader):\n",
    "            inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "            target = target.to(device)\n",
    "            \n",
    "            pred, expert_outs = model(inputs)\n",
    "            loss = hybrid_loss(pred, target, expert_outs)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch} Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 评估指标 ==================== \n",
    "def sharpe_ratio(returns, risk_free=0.0):\n",
    "    excess_returns = returns - risk_free\n",
    "    return excess_returns.mean() / excess_returns.std()\n",
    "\n",
    "def max_drawdown(returns):\n",
    "    cumulative = returns.cumsum()\n",
    "    peak = cumulative.expanding(min_periods=1).max()\n",
    "    drawdown = (peak - cumulative).max()\n",
    "    return drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 维度跟踪 ===\n",
      "卷积后维度: torch.Size([2, 24, 16])\n",
      "LSTM后维度: torch.Size([2, 24, 64])\n",
      "Proj后维度: torch.Size([2, 24, 32])\n",
      "输入维度: torch.Size([2, 24, 4])\n",
      "最终输出维度: torch.Size([2, 1])\n",
      "输入维度: torch.Size([2, 24, 4])\n",
      "测试通过，输出维度: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "def test_conv_layer():\n",
    "    # 模拟输入 (batch=2, seq=24, features=4)\n",
    "    test_input = torch.randn(2, 24, 4)\n",
    "    expert = ScaleAwareExpert(input_dim=4, scale_type='30min')\n",
    "    \n",
    "    # 添加维度跟踪\n",
    "    print(\"=== 维度跟踪 ===\")\n",
    "    x = expert.conv(test_input.permute(0,2,1)).permute(0,2,1)\n",
    "    print(f\"卷积后维度: {x.shape}\")  # 应显示[2,24,16]\n",
    "    \n",
    "    x, _ = expert.lstm(x)\n",
    "    print(f\"LSTM后维度: {x.shape}\")  # 应显示[2,24,64]\n",
    "    \n",
    "    x = expert.proj(x)\n",
    "    print(f\"Proj后维度: {x.shape}\")  # 应显示[2,24,32]\n",
    "    \n",
    "    output = expert(test_input)\n",
    "    print(f\"最终输出维度: {output.shape}\")  # 应显示[2,1]\n",
    "    # 前向传播检查\n",
    "    try:\n",
    "        output = expert(test_input)\n",
    "        print(f\"测试通过，输出维度: {output.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"测试失败: {str(e)}\")\n",
    "\n",
    "test_conv_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 低频专家维度跟踪 ===\n",
      "投影后维度: torch.Size([2, 24, 4])\n",
      "转置后维度: torch.Size([24, 2, 4])\n",
      "Transformer后维度: torch.Size([24, 2, 4])\n",
      "输入维度: torch.Size([2, 24, 4])\n",
      "最终输出维度: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# 测试低频专家\n",
    "def test_low_freq_expert():\n",
    "    test_input = torch.randn(2, 24, 4)\n",
    "    expert = ScaleAwareExpert(input_dim=4, scale_type='4hour')\n",
    "    \n",
    "    print(\"=== 低频专家维度跟踪 ===\")\n",
    "    x = expert.proj_in(test_input)\n",
    "    print(f\"投影后维度: {x.shape}\")  # [2,24,4]\n",
    "    \n",
    "    x = x.permute(1,0,2)\n",
    "    print(f\"转置后维度: {x.shape}\")  # [24,2,4]\n",
    "    \n",
    "    x = expert.transformer(x)\n",
    "    print(f\"Transformer后维度: {x.shape}\")  # [24,2,4]\n",
    "    \n",
    "    output = expert(test_input)\n",
    "    print(f\"最终输出维度: {output.shape}\")  # [2,1]\n",
    "\n",
    "test_low_freq_expert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
