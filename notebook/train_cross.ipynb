{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)  # 设置 matplotlib 日志级别为 WARNING\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib.font_manager\")\n",
    "\n",
    "matplotlib.rcParams['font.family']= ['Songti SC']  # 使用黑体-简\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False # 解决负号显示问题\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
    "\n",
    "def create_sequneces(X, y, time_steps=24):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\"\"\"数据增强\"\"\"\n",
    "def moving_average_smoothing(series, window_size=3):\n",
    "    if series.ndim == 1:  # 处理一维情况\n",
    "        series = series.reshape(-1, 1)\n",
    "    smoothed_data = np.empty_like(series)  # 创建一个与原始数据形状相同的空数组\n",
    "    for col in range(series.shape[1]):\n",
    "        # 对每一列(每个特征)进行平滑处理\n",
    "        smoothed_data[:,col] = np.convolve(series[:,col], np.ones(window_size)/window_size, mode='same')\n",
    "    return smoothed_data\n",
    "\n",
    "def random_noise(data, noise_factor=0.01):\n",
    "    \"\"\"随机噪声\"\"\"\n",
    "    noise = noise_factor + np.random.randn(*data.shape)\n",
    "    return data + noise\n",
    "\n",
    "def time_series_shift(series, shift_range=5):\n",
    "    \"\"\"时间序列平移\"\"\"\n",
    "    shift = np.random.randint(-shift_range, shift_range + 1)\n",
    "    return np.roll(series, shift, axis=0)\n",
    "\n",
    "def data_augmentation(X, y, num_augmentations=5):\n",
    "    augmented_X, augmented_y = [], []\n",
    "    for i in range(len(X)):\n",
    "        # 移动平均平滑\n",
    "        augmented_X.append(X[i])\n",
    "        augmented_y.append(y[i])\n",
    "        for _ in range(num_augmentations):\n",
    "            # 增强方法1 平滑处理\n",
    "            X_smooth = moving_average_smoothing(X[i])\n",
    "            # 增加方法2 添加噪声\n",
    "            X_noise = random_noise(X_smooth)\n",
    "            # 增加方法3 时间偏移\n",
    "            X_shift = time_series_shift(X_noise)\n",
    "            augmented_X.append(X_shift)\n",
    "            augmented_y.append(y[i])\n",
    "    return np.array(augmented_X), np.array(augmented_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv', parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target ='close'\n",
    "features = df.drop(columns=['date', target]).values\n",
    "X = features.copy()\n",
    "y = df[target].copy().values.reshape(-1, 1)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X)\n",
    "y_train_scaled = scaler_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"划分数据集...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y_train_scaled, test_size=0.3, random_state=42, shuffle=False)\n",
    "X_val,X_test, y_val,y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "将时间序列数据划分为多个窗口，每个窗口包含过去window_size个时间步的数据和下一个时间步的标签。\n",
    "\"\"\"\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'R2']\n",
    "window_sizes = [10, 30, 60, 90, 120]\n",
    "lstm_params={\"layers\":2, 'units': 64,  'dropout_rate': 0.3, 'learning_rate': 0.0001, 'clipvalue': 0.5, 'epochs': 20,'batch_size': 64, 'input_window': 120}\n",
    "layers = lstm_params.get('layers')\n",
    "model_name=f\"Cross-LSTM-w{lstm_params.get('input_window')}-layers{layers}-u{lstm_params.get('units')}-d{lstm_params.get('dropout_rate')}-l{lstm_params.get('learning_rate')}-c{lstm_params.get('clipvalue')}-e{lstm_params.get('epochs')}-b{lstm_params.get('batch_size')}\"\n",
    "\n",
    "print(\"划分数据集...\")\n",
    "X_train_full, y_train_full = create_sequneces(X_train_scaled, y_train_scaled, lstm_params.get('input_window'))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42, shuffle=False)\n",
    "print(\"数据增强...\")\n",
    "X_train_full_augmented, y_train_full_augmented = data_augmentation(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Origin traning data shape: {X_train.shape}\")\n",
    "print(f\"Augmented traning data shape: {X_train_full_augmented.shape}\")\n",
    "print(\"交叉验证...\")\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size=30)\n",
    "result = {metric: [] for metric in metrics}\n",
    "for fold,(train_index, val_index) in enumerate(tscv.split(X_train_full_augmented)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    X_train_fold, X_val_fold = X_train_full_augmented[train_index], X_train_full_augmented[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_full_augmented[train_index], y_train_full_augmented[val_index]\n",
    "\n",
    "    print(\"构建LSTM模型...\")\n",
    "    print(f\"输入数据形状检查：{X_train_fold.shape}\")  # 应为 (样本数, 时间步, 特征数)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=lstm_params.get('units'), \n",
    "                                input_shape=( X_train_fold.shape[1], X_train_fold.shape[2]), return_sequences=layers > 1, \n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    model.add(tf.keras.layers.Dropout(lstm_params.get('dropout_rate')))\n",
    "    for i in range(1, lstm_params.get('layers')):\n",
    "        print(f\"增加一层layer = {i+1}, return_sequences={layers -1 > i}\")\n",
    "        model.add(tf.keras.layers.LSTM(units=lstm_params.get('units'), return_sequences=(layers -1 > i)))\n",
    "        model.add(tf.keras.layers.Dropout(lstm_params.get('dropout_rate')))\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= lstm_params.get('learning_rate'),\n",
    "                                                    clipvalue=lstm_params.get('clipvalue')), loss='mean_squared_error', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    print(\"训练模型...\")\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=lstm_params.get('epochs'), \n",
    "                        batch_size=lstm_params.get('batch_size'), \n",
    "                        validation_data=(X_val_fold, y_val_fold), verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    print(\"预测模型...\")\n",
    "    predictions = model.predict(X_val_fold)\n",
    "    predicted_prices =  scaler_y.inverse_transform(predictions)\n",
    "    real_prices = scaler_y.inverse_transform(y_train_scaled.reshape(-1, 1))\n",
    "    \"\"\"模型验证和评估\"\"\"\n",
    "    print(\"评估模型...\")\n",
    "    mse = mean_squared_error(real_prices, predicted_prices)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(real_prices, predicted_prices)\n",
    "    r2 = r2_score(real_prices, predicted_prices)\n",
    "    result['MSE'].append(mse)\n",
    "    result['RMSE'].append(rmse)\n",
    "    result['MAE'].append(mae)\n",
    "    result['R2'].append(r2)\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared (R2): {r2}\")\n",
    "\n",
    "    # 打印结果\n",
    "    fig, (ax) = plt.subplots(1,1,figsize=(12, 6))\n",
    "    plt.plot(predicted_prices, label='predicted_prices')\n",
    "    plt.plot(real_prices, label='real_prices')\n",
    "    plt.title('Model Accuracy History')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M\"))\n",
    "    plt.grid(True)\n",
    "    fig.savefig(f'results/model_predicted_prices-{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig2, (ax2) = plt.subplots(1,1,figsize=(12, 6))\n",
    "    plt.plot(predicted_prices[-100:], label='predicted_prices')\n",
    "    plt.plot(real_prices[-100:], label='real_prices')\n",
    "    ax2.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M\"))\n",
    "    plt.title('Model Accuracy History')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \"\"\"打印验证损失曲线\"\"\"\n",
    "    fig2 = plt.figure(figsize=(16, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # 绘制验证损失曲线（如果有验证集）\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # 添加统计信息框\n",
    "    stats_text = f\"\"\"模型验证和评估：\n",
    "    • Mean Squared Error (MSE):{mse}\n",
    "    • Root Mean Squared Error (RMSE):{rmse}\n",
    "    • Mean Absolute Error (MAE):{mae}\n",
    "    • R-squared (R2): {r2}\n",
    "    \"\"\"\n",
    "\n",
    "    plt.annotate(stats_text, \n",
    "                xy=(0.78, 0.85), \n",
    "                xycoords='axes fraction',\n",
    "                bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"#999999\", alpha=0.8))\n",
    "    plt.title(f'Model Training History')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    fig2.savefig(f'results/model_loss-{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"交叉验证结果：{result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
