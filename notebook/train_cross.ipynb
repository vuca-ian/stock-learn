{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)  # 设置 matplotlib 日志级别为 WARNING\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib.font_manager\")\n",
    "\n",
    "matplotlib.rcParams['font.family']= ['Songti SC']  # 使用黑体-简\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False # 解决负号显示问题\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
    "\n",
    "def create_sequneces(X, y, time_steps=24):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\"\"\"数据增强\"\"\"\n",
    "def moving_average_smoothing(series, window_size=3):\n",
    "    if series.ndim == 1:  # 处理一维情况\n",
    "        series = series.reshape(-1, 1)\n",
    "    smoothed_data = np.empty_like(series)  # 创建一个与原始数据形状相同的空数组\n",
    "    for col in range(series.shape[1]):\n",
    "        # 对每一列(每个特征)进行平滑处理\n",
    "        smoothed_data[:,col] = np.convolve(series[:,col], np.ones(window_size)/window_size, mode='same')\n",
    "    return smoothed_data\n",
    "\n",
    "def random_noise(data, noise_factor=0.01):\n",
    "    \"\"\"随机噪声\"\"\"\n",
    "    noise = noise_factor + np.random.randn(*data.shape)\n",
    "    return data + noise\n",
    "\n",
    "def time_series_shift(series, shift_range=5):\n",
    "    \"\"\"时间序列平移\"\"\"\n",
    "    shift = np.random.randint(-shift_range, shift_range + 1)\n",
    "    return np.roll(series, shift, axis=0)\n",
    "\n",
    "def data_augmentation(X, y, num_augmentations=5):\n",
    "    augmented_X, augmented_y = [], []\n",
    "    for i in range(len(X)):\n",
    "        # 移动平均平滑\n",
    "        augmented_X.append(X[i])\n",
    "        augmented_y.append(y[i])\n",
    "        for _ in range(num_augmentations):\n",
    "            # 增强方法1 平滑处理\n",
    "            X_smooth = moving_average_smoothing(X[i])\n",
    "            # 增加方法2 添加噪声\n",
    "            X_noise = random_noise(X_smooth)\n",
    "            # 增加方法3 时间偏移\n",
    "            X_shift = time_series_shift(X_noise)\n",
    "            augmented_X.append(X_shift)\n",
    "            augmented_y.append(y[i])\n",
    "    return np.array(augmented_X), np.array(augmented_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>count</th>\n",
       "      <th>amount</th>\n",
       "      <th>EMA20</th>\n",
       "      <th>EMA100</th>\n",
       "      <th>...</th>\n",
       "      <th>close_volatility</th>\n",
       "      <th>Volatility_10</th>\n",
       "      <th>close_Volume_volatility</th>\n",
       "      <th>Volume_volatility_10</th>\n",
       "      <th>UpperBB</th>\n",
       "      <th>MiddleBB</th>\n",
       "      <th>LowerBB</th>\n",
       "      <th>return_lag1</th>\n",
       "      <th>return_lag3</th>\n",
       "      <th>return_lag5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-28 13:30:00</td>\n",
       "      <td>292.37</td>\n",
       "      <td>292.74</td>\n",
       "      <td>292.37</td>\n",
       "      <td>292.75</td>\n",
       "      <td>160.682134</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.5489</td>\n",
       "      <td>294.090399</td>\n",
       "      <td>294.843200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.016358</td>\n",
       "      <td>0.208714</td>\n",
       "      <td>20.221269</td>\n",
       "      <td>298.296695</td>\n",
       "      <td>294.6315</td>\n",
       "      <td>290.966305</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>-0.007560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-28 14:00:00</td>\n",
       "      <td>292.73</td>\n",
       "      <td>291.96</td>\n",
       "      <td>291.86</td>\n",
       "      <td>292.75</td>\n",
       "      <td>176.740890</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.6049</td>\n",
       "      <td>293.887504</td>\n",
       "      <td>294.786107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002668</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>-0.471551</td>\n",
       "      <td>2.280677</td>\n",
       "      <td>298.160943</td>\n",
       "      <td>294.4110</td>\n",
       "      <td>290.661057</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>-0.002630</td>\n",
       "      <td>-0.002562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-28 14:30:00</td>\n",
       "      <td>291.97</td>\n",
       "      <td>292.91</td>\n",
       "      <td>291.20</td>\n",
       "      <td>294.59</td>\n",
       "      <td>234.267629</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.8014</td>\n",
       "      <td>293.794408</td>\n",
       "      <td>294.748956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>0.761039</td>\n",
       "      <td>2.320067</td>\n",
       "      <td>297.903752</td>\n",
       "      <td>294.2305</td>\n",
       "      <td>290.557248</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.002018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-28 15:00:00</td>\n",
       "      <td>292.94</td>\n",
       "      <td>292.94</td>\n",
       "      <td>291.29</td>\n",
       "      <td>294.58</td>\n",
       "      <td>133.953471</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.4573</td>\n",
       "      <td>293.713036</td>\n",
       "      <td>294.713135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.013719</td>\n",
       "      <td>2.177855</td>\n",
       "      <td>297.630285</td>\n",
       "      <td>294.0575</td>\n",
       "      <td>290.484715</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-28 15:30:00</td>\n",
       "      <td>292.89</td>\n",
       "      <td>292.87</td>\n",
       "      <td>291.20</td>\n",
       "      <td>292.89</td>\n",
       "      <td>271.680139</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.9288</td>\n",
       "      <td>293.632747</td>\n",
       "      <td>294.676638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>-0.064928</td>\n",
       "      <td>1.628303</td>\n",
       "      <td>297.295646</td>\n",
       "      <td>293.8750</td>\n",
       "      <td>290.454354</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.001744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date    open   close     low    high      volume  count  \\\n",
       "0  2017-10-28 13:30:00  292.37  292.74  292.37  292.75  160.682134   20.0   \n",
       "1  2017-10-28 14:00:00  292.73  291.96  291.86  292.75  176.740890   22.0   \n",
       "2  2017-10-28 14:30:00  291.97  292.91  291.20  294.59  234.267629   22.0   \n",
       "3  2017-10-28 15:00:00  292.94  292.94  291.29  294.58  133.953471   21.0   \n",
       "4  2017-10-28 15:30:00  292.89  292.87  291.20  292.89  271.680139   23.0   \n",
       "\n",
       "   amount       EMA20      EMA100  ...  close_volatility  Volatility_10  \\\n",
       "0  0.5489  294.090399  294.843200  ...          0.001299       0.016358   \n",
       "1  0.6049  293.887504  294.786107  ...         -0.002668       0.013005   \n",
       "2  0.8014  293.794408  294.748956  ...          0.003249       0.013102   \n",
       "3  0.4573  293.713036  294.713135  ...          0.000102       0.012696   \n",
       "4  0.9288  293.632747  294.676638  ...         -0.000239       0.009353   \n",
       "\n",
       "   close_Volume_volatility  Volume_volatility_10     UpperBB  MiddleBB  \\\n",
       "0                 0.208714             20.221269  298.296695  294.6315   \n",
       "1                -0.471551              2.280677  298.160943  294.4110   \n",
       "2                 0.761039              2.320067  297.903752  294.2305   \n",
       "3                 0.013719              2.177855  297.630285  294.0575   \n",
       "4                -0.064928              1.628303  297.295646  293.8750   \n",
       "\n",
       "      LowerBB  return_lag1  return_lag3  return_lag5  \n",
       "0  290.966305     0.001300     0.001437    -0.007560  \n",
       "1  290.661057    -0.002664    -0.002630    -0.002562  \n",
       "2  290.557248     0.003254     0.001881     0.002018  \n",
       "3  290.484715     0.000102     0.000683     0.000717  \n",
       "4  290.454354    -0.000239     0.003117     0.001744  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv', parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target ='close'\n",
    "features = df.drop(columns=['date', target]).values\n",
    "X = features.copy()\n",
    "y = df[target].copy().values.reshape(-1, 1)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X)\n",
    "y_train_scaled = scaler_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "划分数据集...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "print(\"划分数据集...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "划分数据集...\n",
      "数据增强...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "将时间序列数据划分为多个窗口，每个窗口包含过去window_size个时间步的数据和下一个时间步的标签。\n",
    "\"\"\"\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'R2']\n",
    "window_sizes = [10, 30, 60, 90, 120]\n",
    "lstm_params={\"layers\":2, 'units': 64,  'dropout_rate': 0.3, 'learning_rate': 0.0001, 'clipvalue': 0.5, 'epochs': 20,'batch_size': 64, 'input_window': 120}\n",
    "layers = lstm_params.get('layers')\n",
    "model_name=f\"Cross-LSTM-w{lstm_params.get('input_window')}-layers{layers}-u{lstm_params.get('units')}-d{lstm_params.get('dropout_rate')}-l{lstm_params.get('learning_rate')}-c{lstm_params.get('clipvalue')}-e{lstm_params.get('epochs')}-b{lstm_params.get('batch_size')}\"\n",
    "\n",
    "print(\"划分数据集...\")\n",
    "X_train_full, y_train_full = create_sequneces(X_train_scaled, y_train_scaled, lstm_params.get('input_window'))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42, shuffle=False)\n",
    "print(\"数据增强...\")\n",
    "X_train_full_augmented, y_train_full_augmented = data_augmentation(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Origin traning data shape: {X_train.shape}\")\n",
    "print(f\"Augmented traning data shape: {X_train_full_augmented.shape}\")\n",
    "print(\"交叉验证...\")\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size=30)\n",
    "result = {metric: [] for metric in metrics}\n",
    "for fold,(train_index, val_index) in enumerate(tscv.split(X_train_full_augmented)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    X_train_fold, X_val_fold = X_train_full_augmented[train_index], X_train_full_augmented[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_full_augmented[train_index], y_train_full_augmented[val_index]\n",
    "\n",
    "    print(\"构建LSTM模型...\")\n",
    "    print(f\"输入数据形状检查：{X_train_fold.shape}\")  # 应为 (样本数, 时间步, 特征数)\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=lstm_params.get('units'), \n",
    "                                input_shape=( X_train_fold.shape[1], X_train_fold.shape[2]), return_sequences=layers > 1, \n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    model.add(tf.keras.layers.Dropout(lstm_params.get('dropout_rate')))\n",
    "    for i in range(1, lstm_params.get('layers')):\n",
    "        print(f\"增加一层layer = {i+1}, return_sequences={layers -1 > i}\")\n",
    "        model.add(tf.keras.layers.LSTM(units=lstm_params.get('units'), return_sequences=(layers -1 > i)))\n",
    "        model.add(tf.keras.layers.Dropout(lstm_params.get('dropout_rate')))\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= lstm_params.get('learning_rate'),\n",
    "                                                    clipvalue=lstm_params.get('clipvalue')), loss='mean_squared_error', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    print(\"训练模型...\")\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=lstm_params.get('epochs'), \n",
    "                        batch_size=lstm_params.get('batch_size'), \n",
    "                        validation_data=(X_val_fold, y_val_fold), verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    print(\"预测模型...\")\n",
    "    predictions = model.predict(X_val_fold)\n",
    "    predicted_prices =  scaler_y.inverse_transform(predictions)\n",
    "    real_prices = scaler_y.inverse_transform(y_train_scaled.reshape(-1, 1))\n",
    "    \"\"\"模型验证和评估\"\"\"\n",
    "    print(\"评估模型...\")\n",
    "    mse = mean_squared_error(real_prices, predicted_prices)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(real_prices, predicted_prices)\n",
    "    r2 = r2_score(real_prices, predicted_prices)\n",
    "    result['MSE'].append(mse)\n",
    "    result['RMSE'].append(rmse)\n",
    "    result['MAE'].append(mae)\n",
    "    result['R2'].append(r2)\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared (R2): {r2}\")\n",
    "\n",
    "    # 打印结果\n",
    "    fig, (ax) = plt.subplots(1,1,figsize=(12, 6))\n",
    "    plt.plot(predicted_prices, label='predicted_prices')\n",
    "    plt.plot(real_prices, label='real_prices')\n",
    "    plt.title('Model Accuracy History')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M\"))\n",
    "    plt.grid(True)\n",
    "    fig.savefig(f'results/model_predicted_prices-{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "    fig2, (ax2) = plt.subplots(1,1,figsize=(12, 6))\n",
    "    plt.plot(predicted_prices[-100:], label='predicted_prices')\n",
    "    plt.plot(real_prices[-100:], label='real_prices')\n",
    "    ax2.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M\"))\n",
    "    plt.title('Model Accuracy History')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \"\"\"打印验证损失曲线\"\"\"\n",
    "    fig2 = plt.figure(figsize=(16, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    # 绘制验证损失曲线（如果有验证集）\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    # 添加统计信息框\n",
    "    stats_text = f\"\"\"模型验证和评估：\n",
    "    • Mean Squared Error (MSE):{mse}\n",
    "    • Root Mean Squared Error (RMSE):{rmse}\n",
    "    • Mean Absolute Error (MAE):{mae}\n",
    "    • R-squared (R2): {r2}\n",
    "    \"\"\"\n",
    "\n",
    "    plt.annotate(stats_text, \n",
    "                xy=(0.78, 0.85), \n",
    "                xycoords='axes fraction',\n",
    "                bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"#999999\", alpha=0.8))\n",
    "    plt.title(f'Model Training History')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    fig2.savefig(f'results/model_loss-{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"交叉验证结果：{result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
