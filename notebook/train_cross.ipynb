{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import platform\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)  # 设置 matplotlib 日志级别为 WARNING\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib.font_manager\")\n",
    "\n",
    "if platform.system() == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.family'] = ['Songti SC']\n",
    "elif platform.system() == 'Windows':\n",
    "    plt.rcParams['font.family'] = ['SimSun']\n",
    "else:  # Linux\n",
    "    plt.rcParams['font.family'] = ['Noto Sans CJK SC']\n",
    "# matplotlib.rcParams['font.family']= ['Songti SC']  # 使用黑体-简\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False # 解决负号显示问题\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
    "\n",
    "def create_sequneces(X, y, time_steps=24):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\"\"\"数据增强\"\"\"\n",
    "def moving_average_smoothing(series, window_size=5):\n",
    "    if series.ndim == 1:  # 处理一维情况\n",
    "        series = series.reshape(-1, 1)\n",
    "    smoothed_data = np.empty_like(series)  # 创建一个与原始数据形状相同的空数组\n",
    "    for col in range(series.shape[1]):\n",
    "        # 对每一列(每个特征)进行平滑处理\n",
    "        smoothed_data[:,col] = np.convolve(series[:,col], np.ones(window_size)/window_size, mode='same')\n",
    "    return smoothed_data\n",
    "\n",
    "def random_noise(data, noise_factor=0.01):\n",
    "    \"\"\"随机噪声\"\"\"\n",
    "    noise = noise_factor + np.random.randn(*data.shape)\n",
    "    return data + noise\n",
    "\n",
    "def time_series_shift(series, shift_range=5):\n",
    "    \"\"\"时间序列平移\"\"\"\n",
    "    shift = np.random.randint(-shift_range, shift_range + 1)\n",
    "    return np.roll(series, shift, axis=0)\n",
    "\n",
    "def data_augmentation(X, y, num_augmentations=5):\n",
    "    augmented_X, augmented_y = [], []\n",
    "    for i in range(len(X)):\n",
    "        # 移动平均平滑\n",
    "        augmented_X.append(X[i])\n",
    "        augmented_y.append(y[i])\n",
    "        for _ in range(num_augmentations):\n",
    "            # 特征处理（差异化增强）\n",
    "            # X_aug = X[i].copy()\n",
    "            # 随机选择增强方式\n",
    "            # aug_type = np.random.choice(['smooth', 'noise', 'shift', 'combo'])\n",
    "            \n",
    "            # if aug_type in ['smooth', 'combo']:\n",
    "            #     # 动态窗口大小（3-7随机）\n",
    "            #     window = np.random.randint(3, 8)\n",
    "            #     X_aug = moving_average_smoothing(X_aug, window)\n",
    "            \n",
    "            # if aug_type in ['noise', 'combo']:\n",
    "            #     # 自适应噪声强度（0.5%-5%）\n",
    "            #     noise_level = np.random.uniform(0.005, 0.05)\n",
    "            #     X_aug = random_noise(X_aug, noise_level)\n",
    "            \n",
    "            # if aug_type in ['shift', 'combo']:\n",
    "            #     # 随机偏移量（1-3个时间步）\n",
    "            #     shift = np.random.randint(1, 4)\n",
    "            #     X_aug = time_series_shift(X_aug, shift)\n",
    "            \n",
    "            # 目标值同步增强\n",
    "            y_aug = y[i] * np.random.uniform(0.95, 1.05)  # ±5%波动\n",
    "            y_aug += np.random.normal(0, 0.02)  # 添加2%噪声\n",
    "            \n",
    "            # augmented_X.append(X_aug)\n",
    "            augmented_y.append(y_aug)\n",
    "            # 增强方法1 平滑处理\n",
    "            X_smooth = moving_average_smoothing(X[i])\n",
    "            # 增加方法2 添加噪声\n",
    "            X_noise = random_noise(X_smooth)\n",
    "            # 增加方法3 时间偏移\n",
    "            X_shift = time_series_shift(X_noise)\n",
    "            augmented_X.append(X_shift)\n",
    "            # # 同步y增强（示例：添加噪声）\n",
    "            # y_smooth = moving_average_smoothing(y[i])\n",
    "            # y_noise = random_noise(y_smooth)\n",
    "            # y_shift = time_series_shift(y_noise)\n",
    "            # # y_noise = y[i] + np.random.normal(0, 0.01)  # 添加1%噪声\n",
    "            # augmented_y.append(y_shift)\n",
    "    return np.array(augmented_X), np.array(augmented_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv', parse_dates=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target ='close'\n",
    "features = df.drop(columns=['date', target]).values\n",
    "X_origin = features.copy()\n",
    "y_origin = df[target].copy().values.reshape(-1, 1)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_origin)\n",
    "y_train_scaled = scaler_y.fit_transform(y_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lstm_params, X_train_fold):\n",
    "    # 输入层\n",
    "    print(\"构建LSTM模型...\")\n",
    "    layers = lstm_params.get('layers')\n",
    "    units = lstm_params.get('units')\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=units, \n",
    "                                input_shape=( X_train_fold.shape[1], X_train_fold.shape[2]), return_sequences=layers > 1, \n",
    "                                kernel_regularizer=tf.keras.regularizers.l1_l2(0.01, 0.01)))\n",
    "    model.add(tf.keras.layers.Dropout(lstm_params.get('dropout_rate')))\n",
    "    for i in range(1, layers):\n",
    "        print(f\"增加一层layer = {i+1}, return_sequences={layers -1 > i}\")\n",
    "        model.add(tf.keras.layers.LSTM(units=units, return_sequences=(layers -1 > i),\n",
    "                                    activation='tanh',\n",
    "                                    recurrent_activation='sigmoid'))\n",
    "        model.add(tf.keras.layers.Dropout(lstm_params.get('dropout_rate')))\n",
    "    for i in range(lstm_params.get('dense_layer')):\n",
    "        print(f\"增加一层Dense layer = {i+1}\")\n",
    "        model.add(tf.keras.layers.Dense(units=units, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= lstm_params.get('learning_rate'),\n",
    "                                                    clipvalue=lstm_params.get('clipvalue')), \n",
    "                                                    loss='mean_squared_error', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "将时间序列数据划分为多个窗口，每个窗口包含过去window_size个时间步的数据和下一个时间步的标签。\n",
    "\"\"\"\n",
    "metrics = ['MSE', 'RMSE', 'MAE', 'R2']\n",
    " \n",
    "def fit_data(X_train_scaled, y_train_scaled, window_size = 60, layers =3, units = 64, batch_size = 64, epochs= 20, dense_layer=1):\n",
    "    print(f\"窗口大小: {window_size}, LSTM层数: {layers}, 单元数: {units}, 批量大小: {batch_size}, 训练周期: {epochs}, Dense层数: {dense_layer}\")\n",
    "    lstm_params={'layers': layers, 'units': units,  'dropout_rate': 0.3, 'learning_rate': 0.0001, 'clipvalue': 0.5, 'epochs': epochs,'batch_size': batch_size, 'dense_layer': dense_layer}\n",
    "    model_name=f\"Cross-LSTM-win{window_size}-layers{layers}-unit{lstm_params.get('units')}-dense{dense_layer} -epochs{epochs}-b{batch_size}\"\n",
    "\n",
    "    print(\"划分数据集...\")\n",
    "    X_train_full, y_train_full = create_sequneces(X_train_scaled, y_train_scaled, window_size)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "    # print(\"数据增强...\")\n",
    "    # print(f\"Origin traning data shape: {X_train.shape}\")\n",
    "    X_train_full_augmented, y_train_full_augmented = data_augmentation(X_train, y_train)\n",
    "    # print(f\"Augmented traning data shape: {X_train_full_augmented.shape}\")\n",
    "    # print(\"交叉验证...\")\n",
    "    tscv = TimeSeriesSplit(n_splits=5, test_size=30)\n",
    "    result = {metric: [] for metric in metrics}\n",
    "    for fold,(train_index, val_index) in enumerate(tscv.split(X_train_full_augmented)):\n",
    "        print(f\"Fold {fold+1}\")\n",
    "        X_train_fold, X_val_fold = X_train_full_augmented[train_index], X_train_full_augmented[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_full_augmented[train_index], y_train_full_augmented[val_index]\n",
    "\n",
    "        # print(f\"输入数据形状检查：{X_train_fold.shape}\")  # 应为 (样本数, 时间步, 特征数)\n",
    "        model = build_model(lstm_params, X_train_fold)\n",
    "\n",
    "        # print(\"训练模型...\")\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(X_train, y_train, epochs=lstm_params.get('epochs'), \n",
    "                            batch_size=lstm_params.get('batch_size'), \n",
    "                            validation_data=(X_val_fold, y_val_fold), verbose=1, callbacks=[early_stopping])\n",
    "        \n",
    "        # print(\"预测模型...\")\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted_prices =  scaler_y.inverse_transform(predictions)\n",
    "        real_prices = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "        # 在预测阶段使用原始y值\n",
    "        real_raw_prices = scaler_y.inverse_transform(\n",
    "            y_train_scaled[-len(predicted_prices):].reshape(-1,1)\n",
    "        )\n",
    "    # 更直观的对比方式\n",
    "        comparison_df = pd.DataFrame({\n",
    "            'date':df['date'].iloc[-len(real_prices):].values,\n",
    "            'Predicted': predicted_prices.ravel(),\n",
    "            'Actual_Processed Price': real_prices.ravel(), # 数据增强处理后的实际值\n",
    "            'Origin Price': real_raw_prices[-len(real_prices):].ravel() # 原始数据\n",
    "        })\n",
    "        # print(\"\\\\n最后10条价格对比:\")\n",
    "        # print(comparison_df.tail(10).to_markdown(floatfmt=\".2f\"))\n",
    "        \"\"\"模型验证和评估\"\"\"\n",
    "        # print(\"评估模型...\")\n",
    "        mse = mean_squared_error(real_prices, predicted_prices)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(real_prices, predicted_prices)\n",
    "        r2 = r2_score(real_prices, predicted_prices)\n",
    "        result['MSE'].append(mse)\n",
    "        result['RMSE'].append(rmse)\n",
    "        result['MAE'].append(mae)\n",
    "        result['R2'].append(r2)\n",
    "        # print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "        # print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "        # print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "        # print(f\"R-squared (R2): {r2}\")\n",
    "        # results[window_size] = result\n",
    "        # # 打印结果\n",
    "        fig, (ax) = plt.subplots(1,1,figsize=(12, 6))\n",
    "        plt.plot(comparison_df['date'],predicted_prices, label='predicted_prices', linestyle='--')\n",
    "        plt.plot(comparison_df['date'],real_prices, label='real_prices')\n",
    "        plt.title('Model Accuracy History')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "                # # 添加统计信息框\n",
    "        stats_text = f\"\"\"模型验证和评估：\n",
    "        • Mean Squared Error (MSE):{mse}\n",
    "        • Root Mean Squared Error (RMSE):{rmse}\n",
    "        • Mean Absolute Error (MAE):{mae}\n",
    "        • R-squared (R2): {r2}\n",
    "        \"\"\"\n",
    "        \n",
    "        plt.annotate(stats_text, \n",
    "                    xy=(0.78, 0.85), \n",
    "                    xycoords='axes fraction',\n",
    "                    bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"#999999\", alpha=0.8))\n",
    "        fig.autofmt_xdate()  # 自动优化日期显示\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M\"))\n",
    "        plt.grid(True)\n",
    "        fig.savefig(f'results/model_predicted_prices-{model_name}-{fold+1}.png')\n",
    "        plt.show()\n",
    "\n",
    "        fig2, (ax2) = plt.subplots(1,1,figsize=(12, 6))\n",
    "        plt.plot(predicted_prices[-500:], label='predicted_prices')\n",
    "        plt.plot(real_prices[-500:], label='real_prices')\n",
    "        ax2.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M\"))\n",
    "        fig2.autofmt_xdate()  # 自动优化日期显示\n",
    "        plt.title('Model Accuracy History')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # \"\"\"打印验证损失曲线\"\"\"\n",
    "        # fig2 = plt.figure(figsize=(16, 6))\n",
    "        # plt.plot(history.history['loss'], label='Training Loss')\n",
    "        # # 绘制验证损失曲线（如果有验证集）\n",
    "        # plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        # fig2.autofmt_xdate()  # 自动优化日期显示\n",
    "        # ax2.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        # ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M\"))\n",
    "        # # 添加统计信息框\n",
    "        # stats_text = f\"\"\"模型验证和评估：\n",
    "        # • Mean Squared Error (MSE):{mse}\n",
    "        # • Root Mean Squared Error (RMSE):{rmse}\n",
    "        # • Mean Absolute Error (MAE):{mae}\n",
    "        # • R-squared (R2): {r2}\n",
    "        # \"\"\"\n",
    "        \n",
    "        # plt.annotate(stats_text, \n",
    "        #             xy=(0.78, 0.85), \n",
    "        #             xycoords='axes fraction',\n",
    "        #             bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"#999999\", alpha=0.8))\n",
    "        # plt.title(f'Model Training History')\n",
    "        # plt.ylabel('Loss')\n",
    "        # plt.xlabel('Epoch')\n",
    "        # plt.legend()\n",
    "        # plt.grid(True)\n",
    "        # fig2.savefig(f'results/model_loss-{model_name}-{fold+1}.png')\n",
    "        # plt.show()\n",
    "\n",
    "    print(f\"交叉验证结果：{result}\")\n",
    "\n",
    "    return model_name, {\n",
    "        'MSE': np.mean(result['MSE']),\n",
    "        'RMSE': np.mean(result['RMSE']),\n",
    "        'MAE': np.mean(result['MAE']),\n",
    "        'R2': np.mean(result['R2'])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 98ms/step - loss: 0.0027 - mae: 0.0166 - val_loss: 0.0105 - val_mae: 0.0696\n",
      "Epoch 10/20\n",
      "\u001b[1m 18/701\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 183ms/step - loss: 0.0028 - mae: 0.0185"
     ]
    }
   ],
   "source": [
    "window_sizes = [10,30,60,90,120,200]\n",
    "layers = [2, 3,4,5]\n",
    "denes_layers = [1,2,3]\n",
    "units = [64, 128, 256]\n",
    "results = {}  \n",
    "for window_size in window_sizes:\n",
    "    for layer in layers:\n",
    "        for dense_layer in denes_layers:\n",
    "            for unit in units:\n",
    "                model_name,  result = fit_data(X_train_scaled, y_train_scaled, window_size =window_size, layers=layer, dense_layer=dense_layer, units=unit)\n",
    "                results[model_name] = result\n",
    "\n",
    "        \n",
    "print(f'results:\\n {results}')\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'results/results.csv')\n",
    "# print(f\"模型训练完成，模型保存为 {model_name}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 计算每个窗口大小的平均结果\n",
    "# averages = { window_size: {\n",
    "#     metrics:np.mean(results[window_size][metric] for metric in metrics)\n",
    "# } for window_size in window_sizes }\n",
    "\n",
    "# 对指标进行对数变换\n",
    "log_transformed_results = {\n",
    "    window_size:{\n",
    "        'MSE': np.log1p(results[_key]['MSE']),\n",
    "        'RMSE': np.log1p(results[_key]['RMSE']),\n",
    "        'MAE': results[_key]['MAE'],\n",
    "        'R2': results[_key]['R2']\n",
    "    } for _key in results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = [results[model] for model in results]\n",
    "rmse = [np.sqrt(mse[i]) for i in range(len(mse))]\n",
    "mae = [results[model] for model in results]\n",
    "r2 = [results[model] for model in results]\n",
    "results_d = pd.DataFrame({'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2}, index=results.keys())\n",
    "\n",
    "fig6 = plt.subplots(figsize=(10, 6))\n",
    "bar_width = 0.2\n",
    "# 绘制柱状图\n",
    "index = np.arange(len(results))\n",
    "plt.bar(index, mse, bar_width, label='MSE', color='blue')\n",
    "plt.bar(index + bar_width, rmse, bar_width, label='RMSE', color='green')\n",
    "plt.bar(index + 2 * bar_width, mae, bar_width, label='MAE', color='red')\n",
    "plt.bar(index + 3 * bar_width, r2, bar_width, label='R2', color='purple')\n",
    "# 设置标题和标签\n",
    "plt.title('Comparison of Regression Models')\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.ylabel('Metrics Values (Log Scale)')\n",
    "plt.yscale('log')\n",
    "plt.xticks(index + bar_width, results.keys())\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/model_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"Blues\", len(window_sizes))\n",
    "r = np.arange(len(metrics))\n",
    "plt.figure(figsize=(10, 6))\n",
    "barWidth = 0.15 # 每个柱子的宽度\n",
    "for i, (window_size, result) in enumerate(results.items()):\n",
    "    avg_metrics =[log_transformed_results[metric] for metric in metrics]\n",
    "    bars = plt.bar(r + i * barWidth, avg_metrics, width=barWidth, colors=colors[i], edgecolor='white', label=f'Window Size {window_size}')\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), va='bottom', ha='center')\n",
    "plt.xlabel(\"Metrics\", fontweight='bold')\n",
    "plt.ylabel(\"log-transformed / Original Value\", fontweight='bold')\n",
    "plt.xticks([r + barWidth * (len(window_sizes) /2 -0.5) for r in np.arange(len(metrics))], metrics)\n",
    "# 添加统计信息框\n",
    "plt.title(\"Log-Transformed Evaluation Metrics for Different Window Sizes\", fontweight='bold')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
