{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import talib as ta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, concatenate, Layer, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import platform\n",
    "if platform.system() == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.family'] = ['Songti SC']\n",
    "elif platform.system() == 'Windows':\n",
    "    plt.rcParams['font.family'] = ['SimSun']\n",
    "else:  # Linux\n",
    "    plt.rcParams['font.family'] = ['Noto Sans CJK SC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 增强版数据预处理 ==================\n",
    "def preprocess_data(file_path, time_scales=['30min']):\n",
    "\n",
    "    # 技术指标计算\n",
    "    def add_technical_indicators(df):\n",
    "        # 价格特征\n",
    "        # df['price_diff'] = df['close'].diff()\n",
    "        # df['returns'] = df['close'].pct_change()\n",
    "        \n",
    "        # # 波动率指标\n",
    "        # df['volatility_20'] = df['returns'].rolling(20).std()\n",
    "        \n",
    "        # # 技术指标\n",
    "        # df['MA_10'] = df['close'].rolling(10).mean()\n",
    "        # df['RSI'] = ta.RSI(df['close'], window=14)\n",
    "        # df['MACD'], df['Signal'], df['Hist'] = ta.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "        return df.dropna()\n",
    "\n",
    "    # 多尺度特征工程\n",
    "    scaled_data = {}\n",
    "    time_indices = {}  # 新增时间索引字典\n",
    "    for scale in time_scales:\n",
    "        # 重采样\n",
    "        # 读取原始数据\n",
    "        resampled = pd.read_csv(f\"{file_path}/train-{scale}.csv\", parse_dates=['date'], index_col='date')\n",
    "        \n",
    "        # 添加技术指标\n",
    "        resampled = add_technical_indicators(resampled)\n",
    "        # 归一化处理\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaled = scaler.fit_transform(resampled)\n",
    "        \n",
    "        # 构建3D时序数据 [samples, timesteps, features]\n",
    "        seq_length = 60  # 使用60个时间窗口\n",
    "        X, y = [], []\n",
    "        for i in range(len(scaled)-seq_length-1):\n",
    "            X.append(scaled[i:i+seq_length])\n",
    "            y.append(scaled[i+seq_length, 3])  # 预测close价格\n",
    "\n",
    "        X = np.array(X).reshape(-1, seq_length, resampled.shape[1])\n",
    "        scaled_data[scale] = (X, np.array(y))\n",
    "        # scaled_data[scale] = (np.array(X), np.array(y))\n",
    "        # 保存对应的时间索引（后移seq_length+1的位置）\n",
    "        time_indices[scale] = resampled.index[seq_length+1:]\n",
    "    \n",
    "    return scaled_data, scaler, time_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== MoE 模型架构 ==================\n",
    "class ExpertNetwork(Layer):\n",
    "    def __init__(self, units =[64,32], input_dim=None, dense=None, dropout_rate=0.2, **kwargs):\n",
    "        \"\"\"\n",
    "        参数化专家网络\n",
    "        Args:\n",
    "            units (list): LSTM各层单元数，如[64,32]表示两个LSTM层\n",
    "            dropout_rate (float): Dropout比率\n",
    "        \"\"\"\n",
    "        super(ExpertNetwork, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim  # 显式定义输入维度\n",
    "        self.dense_layers = []\n",
    "        self.dropout_stack = []\n",
    "        self.lstm_stack = []\n",
    "        self.dropout_rate = dropout_rate\n",
    "        # 动态创建LSTM层\n",
    "        for i, unit in enumerate(units):\n",
    "            is_last_layer = (i == len(units)-1)\n",
    "            self.lstm_stack.append(\n",
    "                LSTM(unit, \n",
    "                     input_dim=input_dim,  # 关键修改处\n",
    "                     return_sequences=not is_last_layer, \n",
    "                     kernel_regularizer=tf.keras.regularizers.l1_l2(0.01, 0.01),\n",
    "                     recurrent_activation='sigmoid')\n",
    "            )\n",
    "            self.dropout_stack.append(tf.keras.layers.Dropout(dropout_rate))\n",
    "        if dense:\n",
    "            for i in range(len(dense)):\n",
    "                \"\"\"Dense层\"\"\"\n",
    "                self.dense_layers.append(\n",
    "                    tf.keras.layers.Dense(units=dense[i], activation='relu')\n",
    "                )\n",
    "        # 修正最后一层LSTM的return_sequences\n",
    "        self.lstm_stack[-1].return_sequences = False\n",
    "        # 添加形状追踪\n",
    "        self.output_dim = units[-1]  # 记录最后一层LSTM单元数\n",
    "        # 必须显式注册子层才能追踪参数\n",
    "        for i, (lstm, dropout) in enumerate(zip(self.lstm_stack, self.dropout_stack)):\n",
    "            setattr(self, f\"lstm_{i}\", lstm)\n",
    "            setattr(self, f\"dropout_{i}\", dropout)\n",
    "        self.final_dense = Dense(1)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    def build(self, input_shape):\n",
    "        # 显式构建各层\n",
    "        current_shape = input_shape\n",
    "        for i, (lstm, dropout) in enumerate(zip(self.lstm_stack, self.dropout_stack)):\n",
    "            lstm.build(input_shape)\n",
    "            print(f\"LSTM{i}输入形状: {current_shape} -> 输出形状: {lstm.compute_output_shape(current_shape)}\")\n",
    "\n",
    "            dropout.build(lstm.compute_output_shape(current_shape))\n",
    "            current_shape = lstm.compute_output_shape(current_shape)\n",
    "        # 验证最终形状\n",
    "        print(f\"最终Dense层输入形状: {current_shape}\")\n",
    "        # 构建最终Dense层\n",
    "        self.final_dense.build(current_shape)\n",
    "        \n",
    "        # 必须调用父类方法\n",
    "        super().build(input_shape)\n",
    "\n",
    "    \"\"\"重写方法，确认输出形状\"\"\"\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print(f\"input_shape: {input_shape}\")\n",
    "        return (input_shape[0], 1)  # (batch_size, 1)\n",
    "    \"\"\"重写方法，获取配置信息\"\"\"\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"units\": self.units, \"dropout_rate\": self.dropout_rate})\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        assert inputs.shape[-1] == self.input_dim, \\\n",
    "            f\"输入特征维度{inputs.shape[-1]}与网络配置{self.input_dim}不匹配\"\n",
    "        x = inputs\n",
    "         # 添加维度检查\n",
    "        if len(x.shape) == 2:  # 如果输入是二维 (batch, features)\n",
    "            x = tf.expand_dims(x, axis=1)  # 变为 (batch, 1, features)\n",
    "        for lstm, dropout in zip(self.lstm_stack[:-1], self.dropout_stack[:-1]):\n",
    "            x = lstm(x)\n",
    "            x = dropout(x)\n",
    "        x = self.lstm_stack[-1](x)\n",
    "        for dense in self.dense_layers:\n",
    "            x = dense(x)\n",
    "        return self.final_dense(x)\n",
    "\n",
    "class MoE(Model):\n",
    "    def __init__(self, num_experts,input_dims, attention_units=32, expert_config =None, time_scales = None, **kwargs):\n",
    "        \"\"\"\n",
    "        可配置的MoE模型\n",
    "        Args:\n",
    "            num_experts (int): 专家数量\n",
    "            expert_config (dict): 专家网络配置字典，包含：\n",
    "                - units: 各专家LSTM层配置（列表的列表）\n",
    "                - dropout_rates: 各专家dropout比率\n",
    "            time_scales (list): 时间尺度列表\n",
    "            attention_units (int): 注意力层单元数\n",
    "        \"\"\"\n",
    "        super(MoE, self).__init__(**kwargs)\n",
    "        # 专家网络默认配置\n",
    "        default_expert_config = {\n",
    "            'units': [[64,32]]*num_experts,\n",
    "            'dropout_rates': [0.2]*num_experts\n",
    "        }\n",
    "        if expert_config:\n",
    "            default_expert_config.update(expert_config)\n",
    "\n",
    "        self.experts = [ExpertNetwork(units=default_expert_config['units'][i],\n",
    "                                      input_dim=input_dims[i],  # 添加输入维度参数\n",
    "                                      dropout_rate=default_expert_config['dropout_rates'][i]\n",
    "                                      ) for i in range(num_experts)]\n",
    "        # 注意力层\n",
    "        self.attention = Attention(use_scale=True, score_mode=\"dot\", \n",
    "                                   dropout = default_expert_config.get('attention_dropout', 0.1))\n",
    "        # 门控层\n",
    "        self.gate = Dense(num_experts, activation='softmax',kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "        self.final_dense = Dense(1,  \n",
    "                                 activation='linear',\n",
    "                                 kernel_initializer='he_normal')\n",
    "        self.time_scales = time_scales or []\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "         # 显式构建每个专家的输入处理路径\n",
    "        self.expert_inputs = []\n",
    "        for i, shape in enumerate(input_shapes):\n",
    "            expert_input = Input(shape=shape[1:], name=f\"expert_{i}_input\")\n",
    "            self.expert_inputs.append(expert_input)\n",
    "            processed = self.experts[i](expert_input)\n",
    "            self.experts[i].built = True  # 强制标记为已构建\n",
    "\n",
    "        # 显式定义所有层的输入形状\n",
    "        self.attention.build(input_shape=[(None, 1, len(self.experts)), (None, 1, len(self.experts)), (None, 1, len(self.experts))])\n",
    "        self.gate.build(input_shape=(None, len(self.experts)))\n",
    "        self.final_dense.build(input_shape=(None, len(self.experts)))\n",
    "\n",
    "        super().build(input_shapes)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # 如果inputs是一个包含单个元组的列表，先解包\n",
    "        if isinstance(inputs, tuple) and len(inputs) > 1:\n",
    "            inputs = inputs[0]\n",
    "        if isinstance(inputs, (list, tuple)):\n",
    "            inputs = list(inputs)  # 确保列表格x式\n",
    "        else:\n",
    "            inputs = [inputs]  \n",
    "        for i, inp in enumerate(inputs):\n",
    "            print(f\"专家 {i} 输入形状: {inp.shape} 配置: {self.experts[i].lstm_stack[0].units} units\")\n",
    "            # 添加维度展开处理\n",
    "            if isinstance(inp, tuple):\n",
    "                inp = inp[0]\n",
    "                inputs[i] = inp\n",
    "        # 确保输入对齐\n",
    "        if len(inputs) != len(self.experts):\n",
    "            raise ValueError(f\"输入数量({len(inputs)})与专家数量({len(self.experts)})不匹配\")\n",
    "        \n",
    "        # 专家输出\n",
    "        # 显式调用各专家网络\n",
    "        expert_outputs = [expert(inp) for expert, inp in zip(self.experts, inputs)]\n",
    "\n",
    "        \n",
    "        # 动态路由\n",
    "        concatenated = concatenate(expert_outputs, axis=-1)\n",
    "        # 添加维度扩展（可选，根据Attention层需求）\n",
    "        concatenated = tf.expand_dims(concatenated, axis=1) # 变为 (batch_size, 1, num_experts)\n",
    "        print(f\"Concatenated shape: {concatenated.shape}\")\n",
    "\n",
    "        # 修改后的打印语句\n",
    "        for i, out in enumerate(expert_outputs):\n",
    "            print(f\"Expert {i} output shape: {out.shape}\")\n",
    "\n",
    "        # Attention层 注意力计算\n",
    "        if len(self.experts) > 1:\n",
    "            attention_inputs = [concatenated]*3\n",
    "        else:\n",
    "            attention_inputs = [concatenated, concatenated, concatenated]  # 使用自注意力模式\n",
    "\n",
    "        # 根据需求设置是否使用因果掩码\n",
    "        attention_output = self.attention(inputs=attention_inputs,use_causal_mask=False)\n",
    "\n",
    "        print(f\"Attention输出形状: {attention_output.shape}\")\n",
    "        gated_output = tf.reduce_sum(attention_output * concatenated, axis=1)\n",
    "        \n",
    "        # 门控融合\n",
    "        gate_weights = self.gate(gated_output)\n",
    "        weighted_output = tf.reduce_sum(gate_weights * concatenated, axis=1)\n",
    "        \n",
    "        return self.final_dense(weighted_output)\n",
    "\n",
    "# ================== 模型训练 ==================\n",
    "def train_moe_model(data_dict,  model_config=None,\n",
    "                    train_config=None, epochs= 20):\n",
    "\n",
    "    \"\"\"\n",
    "    可配置的训练函数\n",
    "    Args:\n",
    "        model_config (dict): 模型配置参数，包含：\n",
    "            - num_experts\n",
    "            - expert_config\n",
    "            - attention_units\n",
    "        train_config (dict): 训练配置参数，包含：\n",
    "            - epochs\n",
    "            - batch_size\n",
    "            - learning_rate\n",
    "            - early_stop_patience\n",
    "    \"\"\"\n",
    "    # 合并默认配置\n",
    "    default_model_config = {\n",
    "        'num_experts': len(data_dict),\n",
    "        'expert_config': None,\n",
    "        'attention_units': 32\n",
    "    }\n",
    "    if model_config:\n",
    "        default_model_config.update(model_config)\n",
    "\n",
    "    print(f'当前模型配置：{default_model_config}')\n",
    "    default_train_config = {\n",
    "        'epochs': 50,\n",
    "        'batch_size': 128,\n",
    "        'learning_rate': 0.001,\n",
    "        'optimizer': 'adam',\n",
    "        'early_stop_patience': 5\n",
    "    }\n",
    "    if train_config:\n",
    "        default_train_config.update(train_config)\n",
    "    print(f'当前训练配置：{default_train_config}')\n",
    "    # 初始化模型\n",
    "    input_dims = [data[0].shape[-1] for data in data_dict.values()]\n",
    "    model = MoE(num_experts=default_model_config['num_experts'], \n",
    "                input_dims=input_dims,  # 传入实际特征维度\n",
    "                expert_config=default_model_config['expert_config'],\n",
    "                time_scales=data_dict.keys())\n",
    "    \n",
    "    # 准备多尺度输入数据\n",
    "    X_list = [data[0] for data in data_dict.values()]\n",
    "    y = list(data_dict.values())[0][1]  # 假设所有尺度使用相同目标\n",
    "\n",
    "    # 添加输入层定义\n",
    "    input_shapes = [x.shape[1:] for x in X_list]\n",
    "    # model.build(input_shapes)\n",
    "    model.build([(None,) + shape for shape in input_shapes])  # 显式定义输入形状\n",
    "\n",
    "    print(f\"专家网络参数数量: {model.experts[0].count_params()}\")\n",
    "    # 添加层连接可视化\n",
    "    tf.keras.utils.plot_model(model, show_shapes=True, to_file='model.png')\n",
    "    # 模型编译\n",
    "    optimizer_map = {\n",
    "        'adam': tf.keras.optimizers.Adam,\n",
    "        'adamax': tf.keras.optimizers.Adamax,\n",
    "        'rmsprop': tf.keras.optimizers.RMSprop\n",
    "    }\n",
    "    optimizer = optimizer_map[default_train_config['optimizer']](\n",
    "        learning_rate=default_train_config['learning_rate']\n",
    "    )\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='mse',\n",
    "                metrics=['mae','mse'])\n",
    "    model.summary(expand_nested=True, show_trainable=True)\n",
    "    # 早停策略\n",
    "    es = EarlyStopping(monitor='val_loss', \n",
    "                       patience=default_train_config['early_stop_patience'],\n",
    "                       restore_best_weights=True)\n",
    "\n",
    "    # 模型训练\n",
    "    history = model.fit(X_list, y,\n",
    "                      epochs=default_train_config['epochs'],\n",
    "                      batch_size=default_train_config['batch_size'],\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[es],\n",
    "                      verbose=1)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "data_scaled, scaler, _ = preprocess_data('../data/')\n",
    "# 定义实验配置\n",
    "experiment_config = {\n",
    "    'model_config': {\n",
    "        'num_experts': len(data_scaled),\n",
    "        'expert_config': {\n",
    "            'units': [\n",
    "                [31, 64],  # 专家1的LSTM结构\n",
    "                # [64, 32]    # 专家2的LSTM结构\n",
    "            ],\n",
    "            'dense_layer':[64],\n",
    "            'dropout_rates': [0.3, 0.2],\n",
    "            'attention_dropout': 0.1\n",
    "        },\n",
    "        'attention_units': 64\n",
    "    },\n",
    "    'train_config': {\n",
    "        'epochs': 2,\n",
    "        'batch_size': 256,\n",
    "        'learning_rate': 0.0005,\n",
    "        'optimizer': 'adamax',\n",
    "        'early_stop_patience': 7\n",
    "    }\n",
    "}\n",
    "\n",
    "# 模型训练\n",
    "moe_model, history = train_moe_model(data_scaled,\n",
    "                            model_config=experiment_config['model_config'],\n",
    "                            train_config=experiment_config['train_config'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果分析\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Training Progress')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 模型预测与评估 ==================\n",
    "def evaluate_moe(model, test_file, scaler, time_scales=['30min']):\n",
    "    # 加载测试数据\n",
    "    test_data, _,test_time  = preprocess_data(test_file, time_scales)\n",
    "    \n",
    "    # 准备多尺度测试输入\n",
    "    X_test_list = [data[0] for data in test_data.values()]\n",
    "    y_test = list(test_data.values())[0][1]\n",
    "    time_index = test_time[time_scales[0]]  # 获取主要时间尺度的索引\n",
    "    # 模型预测\n",
    "    predictions = model.predict(X_test_list)\n",
    "    \n",
    "    # 反归一化处理\n",
    "    def inverse_scale(data, scaler, feature_index=3):\n",
    "        data = np.squeeze(data)  # 新增展平操作\n",
    "        dummy = np.zeros(shape=(len(data), scaler.n_features_in_))\n",
    "        dummy[:, feature_index] = data\n",
    "        return scaler.inverse_transform(dummy)[:, feature_index]\n",
    "\n",
    "    # 获取实际价格序列\n",
    "    real_prices = inverse_scale(y_test, scaler)\n",
    "    predicted_prices = inverse_scale(predictions, scaler)\n",
    "\n",
    "    # 计算评估指标\n",
    "    mse = mean_squared_error(real_prices, predicted_prices)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(real_prices, predicted_prices)\n",
    "    r2 = r2_score(real_prices, predicted_prices)\n",
    "    # 返回指标字典\n",
    "    return {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'Predictions': predicted_prices,\n",
    "        'Actuals': real_prices\n",
    "    }, time_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 模型保存\n",
    "# moe_model.save('moe_stock_predictor.h5')\n",
    "\n",
    "result, time_index = evaluate_moe(moe_model, '../data/', scaler)\n",
    "print(f\"model predict result \\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 2000\n",
    "# 可视化对比\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "plt.plot(time_index[-n:],result['Actuals'][-n:], label='Actual Prices', alpha=0.7)\n",
    "plt.plot(time_index[-n:],result['Predictions'][-n:], label='Predicted Prices', linestyle='--')\n",
    "plt.title(f'MoE Model Prediction Results')\n",
    "plt.gcf().autofmt_xdate()  # 自动优化日期显示\n",
    "ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d %H:%M\"))\n",
    "# # 添加统计信息框\n",
    "stats_text = f\"\"\"模型验证和评估：\n",
    "• Mean Squared Error (MSE):{result['MSE']}\n",
    "• Root Mean Squared Error (RMSE):{result['RMSE']}\n",
    "• Mean Absolute Error (MAE):{result['MAE']}\n",
    "• R-squared (R2): {result['R2']}\n",
    "\"\"\"\n",
    "\n",
    "plt.annotate(stats_text, \n",
    "            xy=(0.78, 0.85), \n",
    "            xycoords='axes fraction',\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"#999999\", alpha=0.8))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('moe_prediction_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
